{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"pycharm":{"name":"#%% md\n"},"id":"C00SSzCFYOYA"},"source":["# ML Experiments for Churn"]},{"cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["['Datasets_Churn-Update.ipynb',\n"," 'Data_for_prediction.ipynb',\n"," '.~lock.predictions_2022-01-19 08_30_05.545007.csv#',\n"," 'predictions_2022-01-19 08_30_05.545007.csv',\n"," 'configuration.py',\n"," 'data_to_predict_2022-01-18 16_12_55.449522.csv',\n"," '__pycache__',\n"," '.idea',\n"," 'Results_2022-01-18 17_12_10.040628',\n"," 'retired_people2022-01-18 10:30:52.715565.csv',\n"," 'non_retired_people2022-01-18 10:34:45.437345.csv',\n"," 'Results_2022-01-19 17:39:25.232474',\n"," 'Results_2022-01-19 20:22:09.864107',\n"," 'Churn_ML.ipynb']"]},"metadata":{},"execution_count":1}],"source":["import os\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV   #####Revisar esta librerÃ­a.\n","from sklearn.decomposition import PCA\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report\n","from sklearn.linear_model import LogisticRegression\n","import pickle\n","import datetime\n","\n","from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount= True)\n","os.chdir('/content/drive/MyDrive/Churn/Churn_Alejo') #Thomas & Favio & Juan\n","os.listdir(\"./\")"],"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"KUonaHkJYOYD","executionInfo":{"status":"ok","timestamp":1642686090254,"user_tz":300,"elapsed":18530,"user":{"displayName":"Secondary Faad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07846664160256508484"}},"outputId":"8d9ad042-bd31-4508-e7d7-4aff7e16d75c"}},{"cell_type":"markdown","source":["## 1. Preprocessing\n","Importing the datasets for retired and non retired people\n"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"Zm4GI51CYOYF"}},{"cell_type":"code","execution_count":2,"outputs":[],"source":["df_retired = pd.read_csv(\"retired_people2022-01-18 10:30:52.715565.csv\", index_col=False)\n","df_non_retired = pd.read_csv(\"non_retired_people2022-01-18 10:34:45.437345.csv\", index_col=False)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"rOy5kI6DYOYG","executionInfo":{"status":"ok","timestamp":1642686096353,"user_tz":300,"elapsed":883,"user":{"displayName":"Secondary Faad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07846664160256508484"}}}},{"cell_type":"markdown","source":["#### Preprocessing function"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"bVDmG3DAYOYH"}},{"cell_type":"code","execution_count":3,"outputs":[],"source":["def preprocessing(df_retired, df_non_retired):\n","    #Analysis empty columns\n","    list_retired = []\n","    for column in df_retired.columns:\n","        if df_retired[column].any() == False:\n","            list_retired.append(column)\n","\n","    list_non_retired = []\n","    for column in df_non_retired.columns:\n","        if df_non_retired[column].any() == False:\n","            list_non_retired.append(column)\n","\n","    common_lists = []\n","    for i in list_retired:\n","        if i in list_non_retired:\n","            common_lists.append(i)\n","\n","    #Drop empty columns\n","    df_retired.drop(columns = common_lists, inplace = True)\n","    df_non_retired.drop(columns = common_lists, inplace = True)\n","\n","    #label each set\n","    df_retired['LABEL'] = 1\n","    df_non_retired['LABEL'] = 0\n","\n","    # Merging Data\n","    df_merged = pd.concat([df_retired, df_non_retired], join = 'inner', ignore_index = True)\n","    df_merged.drop(['PERSONA'],axis = 1, inplace=True)\n","\n","    return df_merged, common_lists"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"YBs-anUTYOYK","executionInfo":{"status":"ok","timestamp":1642686159737,"user_tz":300,"elapsed":226,"user":{"displayName":"Secondary Faad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07846664160256508484"}}}},{"cell_type":"code","execution_count":4,"outputs":[],"source":["def normalize_data(df_merged):\n","\n","    labels = df_merged['LABEL']\n","    df_merged_scaled = df_merged.loc[:, df_merged.columns != 'LABEL']\n","\n","    cols_ = df_merged_scaled.columns\n","\n","    scaler = StandardScaler()\n","    scaler.fit(df_merged_scaled)\n","    df_merged_scaled = scaler.transform(df_merged_scaled)\n","\n","    df_merged_scaled = pd.DataFrame(df_merged_scaled, columns=cols_)\n","    df_merged_scaled['LABEL'] = labels\n","\n","    return df_merged_scaled, scaler"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"O_E5ElmIYOYL","executionInfo":{"status":"ok","timestamp":1642686161486,"user_tz":300,"elapsed":236,"user":{"displayName":"Secondary Faad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07846664160256508484"}}}},{"cell_type":"code","execution_count":5,"outputs":[],"source":["def pca(df, components):\n","\n","    labels = df['LABEL']\n","    df_1 = df.loc[:, df.columns != 'LABEL']\n","\n","    pca_ = PCA(n_components = components)\n","    pca_.fit(df_1)\n","    df_1_transformed = pca_.transform(df_1)\n","\n","    df_pca = pd.DataFrame(df_1_transformed)\n","    df_pca['LABEL'] = labels\n","\n","    return df_pca, pca_"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"HlS53VIBYOYM","executionInfo":{"status":"ok","timestamp":1642686163857,"user_tz":300,"elapsed":5,"user":{"displayName":"Secondary Faad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07846664160256508484"}}}},{"cell_type":"markdown","source":["## 2. Training"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"5k8RnZvOYOYM"}},{"cell_type":"markdown","source":["#### SVM"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"QWcufSf8YOYN"}},{"cell_type":"code","execution_count":6,"outputs":[],"source":["def svm_churn(df, param_grid):\n","\n","    ### Train test split FOR NUMERICAL ALGORITHMS: 20% test\n","    X = df.drop(['LABEL'],axis = 1)\n","    y = df['LABEL']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n","\n","    svm = SVC()\n","\n","    grid_search = GridSearchCV(svm, param_grid=param_grid,cv=5,verbose=2,scoring='accuracy', n_jobs=-1)\n","    grid_search.fit(X_train,y_train)\n","\n","    best_model_params = grid_search.best_params_\n","\n","    best_model =   SVC(kernel = best_model_params['kernel'], C = best_model_params['C'],\n","                    class_weight = best_model_params['class_weight'], gamma = best_model_params['gamma'])\n","\n","    best_model.fit(X_train, y_train)\n","\n","    y_pred = best_model.predict(X_test)\n","\n","    print('----------Model report on all classes ----------')\n","    print(classification_report(y_test,y_pred, output_dict=True))\n","\n","    return best_model, classification_report"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"2jY_e7hVYOYN","executionInfo":{"status":"ok","timestamp":1642686172403,"user_tz":300,"elapsed":197,"user":{"displayName":"Secondary Faad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07846664160256508484"}}}},{"cell_type":"markdown","source":["#### Logistic Regression"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"IBbJyswCYOYN"}},{"cell_type":"code","execution_count":7,"outputs":[],"source":["def log_reg_churn(df, grid_param):\n","\n","    ### Train test split FOR NUMERICAL ALGORITHMS: 20% test\n","    X = df.drop(['LABEL'],axis = 1)\n","    y = df['LABEL']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n","\n","    log_reg = LogisticRegression()\n","\n","    grid_search = GridSearchCV(estimator = log_reg, param_grid = grid_param, n_jobs = -1, cv = 5,\n","                               verbose = 2, return_train_score = True, scoring = \"accuracy\")\n","    grid_search.fit(X_train, y_train)\n","\n","    best_model_params = grid_search.best_params_\n","    print(grid_search.best_params_)\n","\n","    best_model = LogisticRegression(C = best_model_params['C'], penalty = best_model_params['penalty'], solver=best_model_params['solver'],\n","                                    max_iter=best_model_params['max_iter'], n_jobs = -1)\n","\n","\n","    best_model.fit(X_train, y_train)\n","\n","    y_pred = best_model.predict(X_test)\n","\n","\n","    print('----------Model report on all classes ----------')\n","    print(classification_report(y_test,y_pred, output_dict=True))\n","\n","    return best_model, classification_report"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Cp21wzcPYOYO","executionInfo":{"status":"ok","timestamp":1642686176360,"user_tz":300,"elapsed":226,"user":{"displayName":"Secondary Faad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07846664160256508484"}}}},{"cell_type":"markdown","source":["#### Neural networks"],"metadata":{"id":"o2wakzvdBHma"}},{"cell_type":"code","source":["# Function to create model, required for KerasClassifier\n","def create_model(\n","    # Default values\n","    activation: 'relu',\n","    dropout_rate : 0,\n","    init_mode: 'uniform',\n","    #weight_constraint: 1,\n","    optimizer: 'adam',\n","    hiden_layers: 2,\n","    units: [2, 2],\n","    X) -> tf.keras.Sequential:\n","    \n","    # Create the model\n","    model = Sequential()\n","    model.add(Dense(X.shape[1], kernel_initializer =  init_mode, activation = activation))\n","    \n","    for i in range(hiden_layers):\n","        model.add(Dense(units = units[i], activation = activation))\n","        \n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(1, kernel_initializer = init_mode, activation = 'sigmoid'))\n","    model.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics = ['accuracy'])\n","    \n","    return model"],"metadata":{"id":"jmYgiWSfDoQh","colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"status":"error","timestamp":1642686187443,"user_tz":300,"elapsed":295,"user":{"displayName":"Secondary Faad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07846664160256508484"}},"outputId":"edf06bf1-bdc6-4752-f8b5-01c90c276e24"},"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-50cf1637fa82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mhiden_layers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0munits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     X) -> tf.keras.Sequential:\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Create the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}]},{"cell_type":"code","source":["def nn_churn(df, grid_param):\n","    #Model creation\n","    model_nn = KerasClassifier(build_fn = create_model)\n","\n","    X = df.drop(['LABEL'], axis = 1)\n","    y = df['LABEL']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n","    \n","    grid_search = GridSearchCV(estimator = model_nn, param_grid = grid_param, n_jobs = -1, \n","                               cv = 5, verbose = 2, return_train_score = True, scoring = 'accuracy')\n","    grid_search.fit(X_train, y_train)\n","\n","    best_model_params = grid_search.best_params_\n","    print(best_model_params)\n","\n","    best_model = create_model(activation = best_model_params['activation'], dropout_rate = best_model_params['dropout_rate'],\n","                              init_mode = best_model_params['init_mode'], optimizer = best_model_params['optimizer'], \n","                              hiden_layers = best_model_params['hiden_layers'], units = best_model_params['units'])\n","\n","    return best_model, classification_report\n"],"metadata":{"id":"Sp2IDH7TBIGd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ML Pipeline"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"EVf89HkzYOYO"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 336 candidates, totalling 1680 fits\n","----------Model report on all classes ----------\n","{'0': {'precision': 0.8309859154929577, 'recall': 0.686046511627907, 'f1-score': 0.751592356687898, 'support': 86}, '1': {'precision': 0.8738317757009346, 'recall': 0.9396984924623115, 'f1-score': 0.9055690072639225, 'support': 199}, 'accuracy': 0.8631578947368421, 'macro avg': {'precision': 0.8524088455969462, 'recall': 0.8128725020451093, 'f1-score': 0.8285806819759103, 'support': 285}, 'weighted avg': {'precision': 0.8609028494627381, 'recall': 0.8631578947368421, 'f1-score': 0.8591058776164204, 'support': 285}}\n","Fitting 5 folds for each of 112 candidates, totalling 560 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","245 fits failed out of a total of 560.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","35 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n","    % (solver, penalty)\n","ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","--------------------------------------------------------------------------------\n","35 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n","    % (solver, penalty)\n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","--------------------------------------------------------------------------------\n","35 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n","    % (solver, penalty)\n","ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n","\n","--------------------------------------------------------------------------------\n","35 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n","    % (solver, penalty)\n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n","\n","--------------------------------------------------------------------------------\n","35 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 459, in _check_solver\n","    solver\n","ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n","\n","--------------------------------------------------------------------------------\n","35 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1473, in fit\n","    % self.l1_ratio\n","ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n","\n","--------------------------------------------------------------------------------\n","35 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n","    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n","ValueError: penalty='none' is not supported for the liblinear solver\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.30228379 0.69771621 0.70035551 0.70035551\n"," 0.83394775 0.70123657        nan        nan        nan        nan\n"," 0.76977742 0.78908726        nan 0.84795966        nan        nan\n"," 0.30228379 0.69771621 0.77679883 0.77679883 0.84183476 0.77503285\n","        nan        nan        nan        nan 0.76977742 0.78908726\n","        nan 0.84795966        nan        nan 0.78647113 0.75571914\n"," 0.85325373 0.85325373 0.84795966 0.85677023        nan        nan\n","        nan        nan 0.76977742 0.78908726        nan 0.84795966\n","        nan        nan 0.83479403 0.83654842 0.85322668 0.85322668\n"," 0.84883685 0.8541116         nan        nan        nan        nan\n"," 0.76977742 0.78908726        nan 0.84884071        nan        nan\n"," 0.8417768  0.84883685 0.83827962 0.83827962 0.83916841 0.84708246\n","        nan        nan        nan        nan 0.76977742 0.78908726\n","        nan 0.84884071        nan        nan 0.82423294 0.8470786\n"," 0.82160136 0.82160136 0.82424453 0.84795966        nan        nan\n","        nan        nan 0.76977742 0.78908726        nan 0.84795966\n","        nan        nan 0.80053327 0.84884071 0.81192905 0.81192905\n"," 0.81017467 0.84884071        nan        nan        nan        nan\n"," 0.76977742 0.78908726        nan 0.84884071]\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.30228465 0.69771535 0.70210926 0.70210926\n"," 0.86665058 0.70232904        nan        nan        nan        nan\n"," 1.         0.9975829         nan 0.93760944        nan        nan\n"," 0.30228465 0.69771535 0.80448077 0.80448077 0.88422456 0.80711692\n","        nan        nan        nan        nan 1.         0.9975829\n","        nan 0.93760944        nan        nan 0.78383083 0.75966587\n"," 0.9059746  0.9059746  0.91256535 0.90575506        nan        nan\n","        nan        nan 1.         0.9975829         nan 0.93782922\n","        nan        nan 0.89718773 0.89586857 0.93717108 0.93717108\n"," 0.93497401 0.93409609        nan        nan        nan        nan\n"," 1.         0.9975829         nan 0.93760944        nan        nan\n"," 0.94551935 0.93585264 0.9532078  0.9532078  0.95188936 0.93738966\n","        nan        nan        nan        nan 1.         0.9975829\n","        nan 0.93760944        nan        nan 0.97407655 0.93782946\n"," 0.96990314 0.96990314 0.96924356 0.93782922        nan        nan\n","        nan        nan 1.         0.9975829         nan 0.93782922\n","        nan        nan 0.98330322 0.93782922 0.98132688 0.98132688\n"," 0.98088756 0.93760944        nan        nan        nan        nan\n"," 1.         0.9975829         nan 0.93760944]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["{'C': 0.01, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga'}\n","----------Model report on all classes ----------\n","{'0': {'precision': 0.828125, 'recall': 0.6162790697674418, 'f1-score': 0.7066666666666667, 'support': 86}, '1': {'precision': 0.8506787330316742, 'recall': 0.9447236180904522, 'f1-score': 0.8952380952380953, 'support': 199}, 'accuracy': 0.8456140350877193, 'macro avg': {'precision': 0.8394018665158371, 'recall': 0.780501343928947, 'f1-score': 0.800952380952381, 'support': 285}, 'weighted avg': {'precision': 0.8438730451694847, 'recall': 0.8456140350877193, 'f1-score': 0.8383358395989975, 'support': 285}}\n"]}],"source":["## Creating the folder\n","dir_str = 'Results_' + str(datetime.datetime.now())\n","os.mkdir(dir_str)\n","\n","## Preprocessing\n","preprocessed_data, common_empty_columns = preprocessing(df_retired, df_non_retired)\n","## Save\n","preprocessed_data.to_csv(os.path.join(dir_str, 'preprocessed_data.csv'))\n","pickle.dump(common_empty_columns, open(os.path.join(dir_str,'common_empty_columns.pkl'), 'wb'))\n","\n","\n","## Normalization\n","scaled_data, scaler = normalize_data(preprocessed_data)\n","## Save\n","scaled_data.to_csv(os.path.join(dir_str,'scaled_data.csv'))\n","pickle.dump(scaler, open(os.path.join(dir_str,'scaler.pkl'), 'wb'))\n","\n","\n","## PCA\n","pca_data, pca_ = pca(scaled_data, 250)\n","## Save\n","pca_data.to_csv(os.path.join(dir_str,'pca_data.csv'))\n","pickle.dump(pca_, open(os.path.join(dir_str,'pca_model.pkl'), 'wb'))\n","\n","##---------------------------------------------------------------------------------------------------------\n","## ML SVM\n","param_grid = {'C':  [0.0001, 0.001,0.01, 0.1, 1, 10, 100],\n","                  'gamma' : ['scale', 'auto', 0.0001, 0.001, 0.01, 0.1, 10, 100],\n","                  'class_weight': ['balanced', None],\n","                  'kernel' : ['sigmoid','poly','rbf']}\n","best_svm, report_svm = svm_churn(pca_data, param_grid)\n","## Save\n","pickle.dump(best_svm, open(os.path.join(dir_str,'svm.sav'), 'wb'))\n","pickle.dump(report_svm, open(os.path.join(dir_str,'svm_metrics.pkl'), 'wb'))\n","\n","\n","##----------------------------------------------------------------------------------------------------------\n","## ML Logistic Regression\n","grid_param = {\"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n","              \"C\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n","              \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", 'saga'],\n","              \"max_iter\": [500]\n","              }\n","best_lr, report_lr = log_reg_churn(pca_data, grid_param)\n","## Save\n","pickle.dump(best_lr, open(os.path.join(dir_str,'lr.sav'), 'wb'))\n","pickle.dump(report_lr, open(os.path.join(dir_str,'lr_metrics.pkl'), 'wb'))"],"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"eAsxRr5jYOYP","executionInfo":{"status":"ok","timestamp":1642624934537,"user_tz":300,"elapsed":1194993,"user":{"displayName":"Secondary Faad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07846664160256508484"}},"outputId":"a50a355e-918a-4184-e709-75ade8abc84a"}},{"cell_type":"markdown","source":["## 4. Inference\n","\n","This just works after you execute the queries to predict"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"zig7k0InYOYQ"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-89473df6f258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_from_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_to_predict_2022-01-18 16:12:55.449522.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PERSONA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_to_predict_2022-01-18 16:12:55.449522.csv'"]}],"source":["df_from_queries = pd.read_csv('data_to_predict_2022-01-18 16:12:55.449522.csv', index_col=False)\n","\n","def inference(df, model, common_lists, scaler, pca_model):\n","\n","    ids = df['PERSONA']\n","    df.drop(['PERSONA'],axis = 1, inplace=True)\n","\n","    df.drop(columns = common_lists, inplace = True)\n","    df_scaled = scaler.transform(df)\n","    data_pca = pca_model.transform(df_scaled)\n","\n","    predictions = model.predict(data_pca)\n","\n","    df_predictions = pd.DataFrame(predictions)\n","    df_predictions['PERSONAS'] = ids\n","\n","    df_predictions.to_csv('predictions_' + str(datetime.datetime.now()) + '.csv')"],"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"bO_EUGu5YOYQ","executionInfo":{"status":"error","timestamp":1642615264529,"user_tz":0,"elapsed":28,"user":{"displayName":"Thomas Clarke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEX8xfdaH01NZ5W0qtQcvRofDHOYMNTHHycgI6=s64","userId":"07094370555623799887"}},"outputId":"656502bf-368c-4e59-f202-6c924d25db14"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["## EXAMPLE\n","\n","folder = 'Results_2022-01-18 17:12:10.040628'\n","common_empty_columns = pickle.load(open(os.path.join(folder, 'common_empty_columns.pkl'),'rb'))\n","scaler = pickle.load(open(os.path.join(folder, 'scaler.pkl'),'rb'))\n","pca_model = pickle.load(open(os.path.join(folder, 'pca_model.pkl'),'rb'))\n","model = pickle.load(open(os.path.join(folder, 'lr.sav'),'rb'))\n","\n","inference(df_from_queries, model, common_empty_columns, scaler, pca_model)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"InP5YSEOYOYR"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[""],"metadata":{"pycharm":{"name":"#%%\n"},"id":"kzm1rPHkYOYR"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"name":"Churn_ML.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}